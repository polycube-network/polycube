/**
* k8sdispatcher API generated from k8sdispatcher.yang
*
* NOTE: This file is auto generated by polycube-codegen
* https://github.com/polycube-network/polycube-codegen
*/


#include "K8sdispatcher.h"
#include "K8sdispatcher_dp.h"

#include <tins/ethernetII.h>
#include <tins/tins.h>

using namespace Tins;

const std::string K8sdispatcher::EBPF_DP_RULES_MAP = "dp_rules";

K8sdispatcher::K8sdispatcher(const std::string name, const K8sdispatcherJsonObject &conf)
        : Cube(conf.getBase(), {k8sdispatcher_code}, {}),
          K8sdispatcherBase(name),
          nodePortRangeLow_{30000},
          nodePortRangeHigh_{32767},
          nattedIp_{0},
          externalIp_{0} {
    logger()->set_pattern("[%Y-%m-%d %H:%M:%S.%e] [K8sDispatcher] [%n] [%l] %v");
    logger()->info("creating K8sDispatcher instance");

    this->inBuilding_ = true;
    this->needReload_ = false;

    this->setNodeportRange(conf.getNodeportRange());
    this->setInternalSrcIp(conf.getInternalSrcIp());
    this->addPortsList(conf.getPorts());

    if (this->needReload_) {
        logger()->trace("performing K8sDispatcher code reloading during instance creation");
        this->reloadConfig();
        logger()->trace("performed K8sDispatcher code reloading during instance creation");
    }

    this->inBuilding_ = false;

    logger()->info("created K8sDispatcher instance");
}

K8sdispatcherJsonObject K8sdispatcher::toJsonObject() {
    K8sdispatcherJsonObject conf;
    try {
        conf.setBase(Cube::to_json());

        logger()->trace("getting natting rule list");
        for (auto &i: getNattingRuleList()) {
            conf.addNattingRule(i->toJsonObject());
        }

        logger()->trace("getting nodeport rule list");
        for (auto &i: getNodeportRuleList()) {
            conf.addNodeportRule(i->toJsonObject());
        }

//        logger()->trace("getting ports list");
//        for (auto &i: getPortsList()) {
//            conf.addPorts(i->toJsonObject());
//        }

        conf.setNodeportRange(getNodeportRange());
    }
    catch (std::exception &ex) {
        logger()->warn("K8sdispatcher::toJsonObject exception: {0}", ex.what());
    }
    return conf;
}

void K8sdispatcher::reloadConfig() {
    std::string flags;

    // ports
    uint16_t frontend = 0;
    uint16_t backend = 0;
    for (auto &it: get_ports()) {
        if (it->getType() == PortsTypeEnum::FRONTEND) frontend = it->index();
        else backend = it->index();
    }
    flags += "#define FRONTEND_PORT " + std::to_string(frontend) + "\n";
    flags += "#define BACKEND_PORT " + std::to_string(backend) + "\n";
    flags += "#define NODEPORT_RANGE_LOW " + std::to_string(nodePortRangeLow_) + "\n";
    flags += "#define NODEPORT_RANGE_HIGH " + std::to_string(nodePortRangeHigh_) + "\n";
    flags += "#define EXTERNAL_IP " + std::to_string(htonl(externalIp_)) + "\n";
    flags += "#define NATTED_IP " + std::to_string(htonl(nattedIp_));

    logger()->debug("reloading code with the following flags:\n{}", flags);

    reload(flags + '\n' + k8sdispatcher_code);

    logger()->trace("reloaded K8sDispatcher code");
}

void K8sdispatcher::update(const K8sdispatcherJsonObject &conf) {
    Cube::set_conf(conf.getBase());

    if (conf.nodeportRangeIsSet()) {
        auto nodeport = conf.getNodeportRange();
        setNodeportRange(nodeport);
    }

    if (conf.internalSrcIpIsSet()) {
        auto internalSrcIp = conf.getInternalSrcIp();
        setInternalSrcIp(internalSrcIp);
    }

    if (conf.portsIsSet()) {
        for (auto &i: conf.getPorts()) {
            auto name = i.getName();
            auto m = getPorts(name);
            m->update(i);
        }
    }
}

K8sdispatcher::~K8sdispatcher() {
    logger()->info("Destroyed K8sdispatcher instance");
}

void K8sdispatcher::setExternalIp(const std::string &value) {
    uint32_t external_ip_subnet;
    externalIpString_ = value;
    parse_cidr(value, &externalIp_, &external_ip_subnet);
}

void K8sdispatcher::parse_cidr(const std::string &cidr, uint32_t *subnet,
                               uint32_t *netmask) {
    std::string net_str = cidr.substr(0, cidr.find("/"));
    std::string mask_len = cidr.substr(cidr.find("/") + 1, std::string::npos);

    *subnet = ip_to_dec(net_str);
    *netmask = 0xFFFFFFFF;
    *netmask <<= 32 - std::stoi(mask_len);
}

uint32_t K8sdispatcher::ip_to_dec(const std::string &ip) {
    // TODO: use uint8_t
    unsigned short a, b, c, d;

    std::sscanf(ip.c_str(), "%hu.%hu.%hu.%hu", &a, &b, &c, &d);
    return (a << 24) + (b << 16) + (c << 8) + d;
}

void K8sdispatcher::packet_in(Ports &port,
                              polycube::service::PacketInMetadata &md,
                              const std::vector<uint8_t> &packet) {
    try {
        switch (static_cast<SlowPathReason>(md.reason)) {
            case SlowPathReason::ARP_REPLY: {
                logger()->debug("received pkt in slowpath - reason: ARP_REPLY");
                EthernetII pkt (&packet[0], packet.size());
                auto backendPort = this->getBackendPort();
                if (backendPort != nullptr) backendPort->send_packet_out(pkt);
            }
            default: {
                logger()->error("not valid reason {0} received", md.reason);
            }
        }
    } catch (const std::exception &e) {
        logger()->error("exception during slowpath packet processing: '{0}'", e.what());
    }
}

std::shared_ptr<Ports> K8sdispatcher::getPorts(const std::string &name) {
    return get_port(name);
}

std::vector<std::shared_ptr<Ports>> K8sdispatcher::getPortsList() {
    return get_ports();
}

void K8sdispatcher::addPorts(const std::string &name, const PortsJsonObject &conf) {
    try {
        PortsTypeEnum type = conf.getType();
        auto ipIsSet = conf.ipIsSet();

        // consistency check
        if (get_ports().size() == 2) throw std::runtime_error("reached maximum number of ports");
        if (type == PortsTypeEnum::FRONTEND) {
            if (!ipIsSet) throw std::runtime_error("the IP address is mandatory for a FRONTEND port");
            if (this->getFrontendPort() != nullptr) throw std::runtime_error("there is already a FRONTEND port");
        } else {
            if (ipIsSet) throw std::runtime_error("the IP address in not allowed for a BACKEND port");
            if (this->getBackendPort() != nullptr) throw std::runtime_error("there is already a BACKEND port");
        }

        add_port<PortsJsonObject>(name, conf);

        // setting external IP if port_type == FRONTEND and reload code if needed
        if (type == PortsTypeEnum::FRONTEND) this->setExternalIp(conf.getIp());
        if (get_ports().size() == 2) {
            if (this->inBuilding_) this->needReload_ = true;
            else this->reloadConfig();
        };
    } catch (std::runtime_error &ex) {
        logger()->warn("failed to add port {0}: {1}", name, ex.what());
        throw;
    }
}

// Basic default implementation, place your extension here (if needed)
void K8sdispatcher::addPortsList(const std::vector<PortsJsonObject> &conf) {
    for (auto &i: conf) {
        std::string name_ = i.getName();
        addPorts(name_, i);
    }
}

// Basic default implementation, place your extension here (if needed)
void K8sdispatcher::replacePorts(const std::string &name, const PortsJsonObject &conf) {
    delPorts(name);
    std::string name_ = conf.getName();
    addPorts(name_, conf);
}

// Basic default implementation, place your extension here (if needed)
void K8sdispatcher::delPorts(const std::string &name) {
    throw std::runtime_error("K8sdispatcher::delPorts: Method not allowed");
}

// Basic default implementation, place your extension here (if needed)
void K8sdispatcher::delPortsList() {
    throw std::runtime_error("K8sdispatcher::delPortsList: Method not allowed");
}

uint16_t K8sdispatcher::protoStrToInt(const std::string &proto) {
    if (proto == "icmp" || proto == "ICMP") {
        return IPPROTO_ICMP;
    }
    if (proto == "tcp" || proto == "TCP") {
        return IPPROTO_TCP;
    }
    if (proto == "udp" || proto == "UDP") {
        return IPPROTO_UDP;
    }
    return -1;
}

std::string K8sdispatcher::protoIntToStr(const uint16_t proto) {
    switch (proto) {
        case IPPROTO_ICMP:
            return "ICMP";
        case IPPROTO_TCP:
            return "TCP";
        case IPPROTO_UDP:
            return "UDP";
        default:
            // Never happens
            return "UNKNOWN";
    }
}

int K8sdispatcher::serviceTypeToInt(const NodeportRuleServiceTypeEnum &serviceType) {
    return serviceType == NodeportRuleServiceTypeEnum::CLUSTER ? 4 : 3;
}

std::string K8sdispatcher::getInternalSrcIp() {
    return nattedIpString_;
}

void K8sdispatcher::setInternalSrcIp(const std::string &value) {
    this->nattedIpString_ = value;
    this->nattedIp_ = ip_to_dec(value);
    if (this->inBuilding_) this->needReload_ = true;
    else this->reloadConfig();
}

std::shared_ptr<NattingRule>
K8sdispatcher::getNattingRule(const std::string &internalSrc, const std::string &internalDst,
                              const uint16_t &internalSport, const uint16_t &internalDport, const std::string &proto) {
    try {
        auto table = get_hash_table<st_k, st_v>("egress_session_table");
        st_k map_key{
                .src_ip = polycube::service::utils::ip_string_to_nbo_uint(internalSrc),
                .dst_ip = polycube::service::utils::ip_string_to_nbo_uint(internalDst),
                .src_port = htons(internalSport),
                .dst_port = htons(internalDport),
                .proto = uint8_t(std::stol(proto)),
        };

        st_v value = table.get(map_key);

        std::string newIp = polycube::service::utils::nbo_uint_to_ip_string(value.new_ip);
        uint16_t newPort = value.new_port;
        uint8_t originatingRule = value.originating_rule_type;;
        auto entry = std::make_shared<NattingRule>(
                *this, internalSrc, internalDst, internalSport, internalDport,
                K8sdispatcher::protoStrToInt(proto), newIp, newPort);
        return entry;
    } catch (std::exception &e) {
        throw std::runtime_error("Natting table entry not found");
    }
}

std::vector<std::shared_ptr<NattingRule>> K8sdispatcher::getNattingRuleList() {
    std::vector<std::shared_ptr<NattingRule>> entries;
    try {
        auto table = get_hash_table<st_k, st_v>("egress_session_table");
        auto map_entries = table.get_all();
        for (auto &pair: map_entries) {
            auto key = pair.first;
            auto value = pair.second;

            auto entry = std::make_shared<NattingRule>(
                    *this, polycube::service::utils::nbo_uint_to_ip_string(key.src_ip),
                    polycube::service::utils::nbo_uint_to_ip_string(key.dst_ip), ntohs(key.src_port),
                    ntohs(key.dst_port), key.proto,
                    polycube::service::utils::nbo_uint_to_ip_string(value.new_ip), ntohs(value.new_port));

            entries.push_back(entry);
        }
    } catch (std::exception &e) {
        throw std::runtime_error("Unable to get the natting table");
    }
    return entries;
}

void K8sdispatcher::addNattingRule(const std::string &internalSrc, const std::string &internalDst,
                                   const uint16_t &internalSport, const uint16_t &internalDport,
                                   const std::string &proto, const NattingRuleJsonObject &conf) {
    logger()->warn("K8sdispatcher::addNattingRule: Method not implemented");
}

void K8sdispatcher::addNattingRuleList(const std::vector<NattingRuleJsonObject> &conf) {
    for (auto &i: conf) {
        addNattingRule(
                i.getInternalSrc(), i.getInternalDst(),
                i.getInternalSport(), i.getInternalDport(),
                i.getProto(), i
        );
    }
}

void K8sdispatcher::updateNodeportRuleList(const std::vector<NodeportRuleJsonObject> &conf) {
    logger()->info("received request for NodePort rules updating");
    try {
        for (auto &i: conf) {
            getNodeportRule(i.getNodeportPort(), i.getProto())->update(i);
        }
    }
    catch (std::exception &ex) {
        logger()->warn("failed update NodePort rule: {}", ex.what());
        throw std::runtime_error("failed to update NodePort rule");
    }
    logger()->info("updated NodePort rules");
}

void K8sdispatcher::replaceNattingRule(const std::string &internalSrc, const std::string &internalDst,
                                       const uint16_t &internalSport, const uint16_t &internalDport,
                                       const std::string &proto, const NattingRuleJsonObject &conf) {
    logger()->warn("K8sdispatcher::replaceNattingRule: Method not implemented");

}

void K8sdispatcher::delNattingRule(const std::string &internalSrc, const std::string &internalDst,
                                   const uint16_t &internalSport, const uint16_t &internalDport,
                                   const std::string &proto) {
    logger()->warn("K8sdispatcher::delNattingRule: Method not implemented");
}

void K8sdispatcher::delNattingRuleList() {
    auto egress_table = get_hash_table<st_k, st_v>("egress_session_table");
    egress_table.remove_all();
    auto ingress_table = get_hash_table<st_k, st_v>("ingress_session_table");
    ingress_table.remove_all();
    logger()->info("flushed natting tables");
}

std::shared_ptr<NodeportRule> K8sdispatcher::getNodeportRule(const uint16_t &nodeportPort, const std::string &proto) {
    logger()->debug("received a request to read a NodePort rule");
    NodeportKey key = NodeportKey(proto, nodeportPort);
    if (nodePortMap_.count(key) == 0) {
        logger()->error("there are no entries associated with that key");
    }
    return std::shared_ptr<NodeportRule>(&nodePortMap_.at(key), [](NodeportRule *) {});
}

std::vector<std::shared_ptr<NodeportRule>> K8sdispatcher::getNodeportRuleList() {
    std::vector<std::shared_ptr<NodeportRule>> services_vect;

    for (auto &it: nodePortMap_) {
        NodeportKey key = it.first;
        services_vect.push_back(getNodeportRule(std::get<1>(key), std::get<0>(key)));
    }

    return services_vect;
}

void K8sdispatcher::addNodeportRule(
        const uint16_t &nodeportPort, const std::string &proto, const NodeportRuleJsonObject &conf
) {
    logger()->info("received a request to add a NodePort rule");
    NodeportKey key = NodeportKey(proto, nodeportPort);

    if (this->nodePortMap_.count(key) == 1) {
        logger()->error("the NodePort rule already exists");
        throw std::runtime_error("the NodePort rule already exists");
    }

    NodeportRule rule = NodeportRule(*this, conf);
    if (!nodePortMap_.insert(std::make_pair(key, rule)).second) {
        throw std::runtime_error("failed to correctly add the NodePort rule");
    }

    try {
        logger()->trace("retrieving NodePort rules kernel map");
        auto dp_rules = get_hash_table<dp_k, dp_v>(EBPF_DP_RULES_MAP);
        logger()->trace("retrieved NodePort rules kernel map");
        dp_k key_rule{
                .dummy = 56,
                .external_port = htons(nodeportPort),
                .proto = K8sdispatcher::protoStrToInt(proto),
        };
        dp_v value{
                .internal_port = htons(nodeportPort),
                .entry_type = 4,
        };

        if (rule.getServiceType() == polycube::service::model::NodeportRuleServiceTypeEnum::LOCAL) {
            value.entry_type = 3;
        }
        logger()->trace("storing NodePort rule in NodePort rules kernel map");
        dp_rules.set(key_rule, value);
        logger()->trace("stored NodePort rule in NodePort rules kernel map");
    } catch (std::exception &ex) {
        logger()->warn("failed to store NodePort rule in kernel map: {}", ex.what());
        if (this->nodePortMap_.erase(key) != 1) {
            logger()->error("broken user space NodePort rule map");
        };
        throw std::runtime_error("failed to store NodePort rule in kernel map");
    }
    logger()->info("added NodePort rule");
}

void K8sdispatcher::addNodeportRuleList(const std::vector<NodeportRuleJsonObject> &conf) {
    for (auto &i: conf) {
        addNodeportRule(i.getNodeportPort(), i.getProto(), i);
    }
}

// Basic default implementation, place your extension here (if needed)
void K8sdispatcher::replaceNodeportRule(const uint16_t &nodeportPort, const std::string &proto,
                                        const NodeportRuleJsonObject &conf) {
    delNodeportRule(nodeportPort, proto);
    addNodeportRule(nodeportPort, proto, conf);
}

void K8sdispatcher::replaceNodeportRuleList(const std::vector<NodeportRuleJsonObject> &conf) {
    delNodeportRuleList();
    addNodeportRuleList(conf);
}

void K8sdispatcher::delNodeportRule(const uint16_t &nodeportPort, const std::string &proto) {
    logger()->info("received a request to delete a NodePort rule");
    NodeportKey key = NodeportKey(proto, nodeportPort);

    if (this->nodePortMap_.count(key) == 0) {
        logger()->error("the NodePort rule doesn't exist");
        throw std::runtime_error("the NodePort rule doesn't exist");
    }

    try {
        logger()->trace("retrieving NodePort rules kernel map");
        auto dp_rules = get_hash_table<dp_k, dp_v>(EBPF_DP_RULES_MAP);
        logger()->trace("retrieved NodePort rules kernel map");
        dp_k key_rule{
                .dummy = 56,
                .external_port = htons(nodeportPort),
                .proto = K8sdispatcher::protoStrToInt(proto),
        };

        dp_rules.remove(key_rule);

        if (this->nodePortMap_.erase(key) == 0) {
            logger()->error("the NodePort rule doesn't exist");
            throw std::runtime_error("the NodePort rule doesn't exist");
        }
    }
    catch (std::exception &ex) {
        logger()->error("failed to delete NodePort rule: {}", ex.what());
        throw std::runtime_error("failed to delete NodePort rule");
    }
    logger()->info("deleted NodePort rule");
}

void K8sdispatcher::delNodeportRuleList() {
    for (auto &it: nodePortMap_) {
        NodeportKey key = it.first;
        delNodeportRule(std::get<1>(key), std::get<0>(key));
    }
}

std::string K8sdispatcher::getNodeportRange() {
    return this->nodePortRange_;
}

void K8sdispatcher::setNodeportRange(const std::string &value) {
    uint16_t low;
    uint16_t high;
    int ret = std::sscanf(value.c_str(), "%"
    SCNu16
    "-%"
    SCNu16, &low, &high);
    if (ret != 2) {
        logger()->error("value {} is not valid for node port range", value);
        throw std::runtime_error("invalid node port range");
    }

    if (low >= high) {
        throw std::runtime_error("invalid node port range");
    }

    this->nodePortRangeLow_ = low;
    this->nodePortRangeHigh_ = high;

    this->nodePortRange_ = value;
    if (this->inBuilding_) this->needReload_ = true;
    else this->reloadConfig();
}

std::shared_ptr<Ports> K8sdispatcher::getFrontendPort() {
    for (auto &it: get_ports()) {
        if (it->getType() == PortsTypeEnum::FRONTEND) {
            return it;
        }
    }
    return nullptr;
}

std::shared_ptr<Ports> K8sdispatcher::getBackendPort() {
    for (auto &it: get_ports()) {
        if (it->getType() == PortsTypeEnum::BACKEND) {
            return it;
        }
    }
    return nullptr;
}